{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b49f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as klayers\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import gradnet\n",
    "from gradnet import layers as glayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "mb = 1\n",
    "x = np.random.random((mb,2))\n",
    "y_ = np.array([[1.0,0.0,0.0]]*mb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e95f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmodel():\n",
    "    inp = klayers.Input((2,), name=\"input\")\n",
    "    l1 = klayers.Dense(2, activation=\"relu\", name=\"l1\")(inp)\n",
    "    l2 = klayers.Dense(3, activation=\"softmax\", name=\"l2\")(l1)\n",
    "    model = keras.Model(inp, l2)\n",
    "    return model\n",
    "\n",
    "def gmodel():\n",
    "    inp = gradnet.Input((2,), name=\"input\")\n",
    "    l1 = glayers.Dense(2, activation=\"relu\", name=\"l1\")([inp])\n",
    "    l2 = glayers.Dense(3, activation=\"linear\", name=\"l2\")([l1])\n",
    "    probs = gradnet.activations.get_activation(\"softmax\")(l2)\n",
    "    model = gradnet.Model([inp], [probs])\n",
    "    model.add_loss(gradnet.losses.get_loss(\"cce\")(probs))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085bd5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "l1 (Dense)                   (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "l2 (Dense)                   (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "l1\n",
      "    [[ 0.3054 -0.8194]\n",
      " [ 1.0733  0.1945]]\n",
      "    [0. 0.]\n",
      "l2\n",
      "    [[ 0.2536 -0.124   0.6177]\n",
      " [-0.2356  0.75   -0.5815]]\n",
      "    [0. 0. 0.]\n",
      "<class 'gradnet.activations.SoftMaxActivation'> [Layer SoftMaxActivation ]\n",
      "<class 'gradnet.activations.LinearActivation'> [Layer LinearActivation ]\n",
      "<class 'gradnet.layers.layers.Dense'> [Dense l2 2->3]\n",
      "l2 weights: [array([[ 0.2536, -0.124 ,  0.6177],\n",
      "       [-0.2356,  0.75  , -0.5815]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n",
      "<class 'gradnet.activations.ReLUActivation'> [Layer ReLUActivation ]\n",
      "<class 'gradnet.layers.layers.Dense'> [Dense l1 2->2]\n",
      "l1 weights: [array([[ 0.3054, -0.8194],\n",
      "       [ 1.0733,  0.1945]], dtype=float32), array([0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "km = kmodel()\n",
    "km.summary()\n",
    "\n",
    "kweights = {}\n",
    "\n",
    "for l in km.layers:\n",
    "    wlst = l.get_weights()\n",
    "    if wlst:\n",
    "        print(l.name)\n",
    "        for w in wlst:\n",
    "            print(\"   \", w)\n",
    "        kweights[l.name] = wlst\n",
    "\n",
    "gm = gmodel()\n",
    "for l in gm.layers:\n",
    "    print(type(l), l)\n",
    "    name = l.Name\n",
    "    if name:\n",
    "        w = kweights[name]\n",
    "        #print(\"keras weight for\", name,\":\", w)\n",
    "        l.set_weights(w)\n",
    "        print(name, \"weights:\", l.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84168bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " [[0.6965 0.2861]]\n",
      "Keras y:\n",
      " [[0.33   0.2712 0.3988]]\n",
      "Gradnet y:\n",
      " [array([[0.33  , 0.2712, 0.3988]])]\n"
     ]
    }
   ],
   "source": [
    "# compare models\n",
    "print(\"x:\\n\", x)\n",
    "ky = km(x).numpy()\n",
    "print(\"Keras y:\\n\", ky)\n",
    "gy = gm.call([x])\n",
    "print(\"Gradnet y:\\n\", gy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3e6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_keras(x, y_, model):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cce = keras.losses.CategoricalCrossentropy()\n",
    "        losses = []\n",
    "        for xi, yi_ in zip(x, y_):\n",
    "            xi = xi[None,:]\n",
    "            yi_ = yi_[None,:]\n",
    "            xi = tf.convert_to_tensor(xi)\n",
    "            yi = model(xi)\n",
    "            #print(\"xi=\", xi, \"  yi_=\", yi_, \"  yi=\", yi)\n",
    "            losses.append(cce(yi_, yi))\n",
    "        total_loss = sum(losses)\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    return [g.numpy() for g in grads]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f616e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras gradients:\n",
      "[[0.0298 0.    ]\n",
      " [0.0122 0.    ]]\n",
      "[0.0428 0.    ]\n",
      "[[-0.3482  0.141   0.2073]\n",
      " [ 0.      0.      0.    ]]\n",
      "[-0.67    0.2712  0.3988]\n"
     ]
    }
   ],
   "source": [
    "kgrads = train_keras(x, y_, km)\n",
    "print(\"Keras gradients:\")\n",
    "for g in kgrads:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd551be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradnet(x, y_, model):\n",
    "    model.reset_losses()\n",
    "    for xi, yi_ in zip(x, y_):\n",
    "        xi = xi[None,:]\n",
    "        yi_ = yi_[None,:]\n",
    "        yi = model.call([xi])\n",
    "        #print(\"call: xi:\", xi, \"  -> yi:\", yi, \"   yi_:\", yi_)\n",
    "        model.backprop(yi_)\n",
    "    return model.layer_gradients() \n",
    "\n",
    "def train_gradnet(x, y_, model):\n",
    "    model.reset_losses()\n",
    "    model.call([x])\n",
    "    model.backprop(y_)\n",
    "    return model.layer_gradients() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fd0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalCrossEntropy: sending grads to: <gradnet.graphs.Link object at 0x7fd2c149ac70> [Layer SoftMaxActivation ]\n",
      "SoftMaxActivation.grads: x: [[ 0.1318 -0.0644  0.321 ]]   y_grads: [[-3.0301 -0.     -0.    ]]   x_grads: [[-0.67    0.2712  0.3988]]\n",
      "Gradnet gradients:\n",
      "[[-0.3482  0.141   0.2073]\n",
      " [ 0.      0.      0.    ]]\n",
      "[-0.67    0.2712  0.3988]\n",
      "[[0.0298 0.    ]\n",
      " [0.0122 0.    ]]\n",
      "[0.0428 0.    ]\n"
     ]
    }
   ],
   "source": [
    "ggrads = train_gradnet(x, y_, gm)\n",
    "print(\"Gradnet gradients:\")\n",
    "for g in ggrads:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7398e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
